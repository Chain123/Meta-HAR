{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "collected data statics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of activity types\n",
      "dict_keys([4, 2, 3, 5])\n",
      "# of users with the coresponding # of activity types\n",
      "dict_values([15, 5, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "data_dir = \"/data/ceph/seqrec/fl_data/www21/data/open-source-version/\"\n",
    "result = {}\n",
    "files = [file for file in os.listdir(data_dir) if \"txt\" in file]\n",
    "for filename in files:\n",
    "    data = open(os.path.join(data_dir, filename))\n",
    "    uid = filename.split(\"_\")[0]\n",
    "    if uid not in result:\n",
    "        result[uid] = {}\n",
    "    for line in data:\n",
    "        act = line.strip().split(\"\\t\")[1]\n",
    "        if act not in result[uid]:\n",
    "            result[uid][act] = 0\n",
    "        result[uid][act] += 1\n",
    "\n",
    "length = []\n",
    "for key in result.keys():\n",
    "    length.append(len(result[key]))\n",
    "\n",
    "print(\"# of activity types\")    \n",
    "print(Counter(length).keys())\n",
    "print(\"# of users with the coresponding # of activity types\")    \n",
    "print(Counter(length).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Feature extraction.\n",
    "    1. mag\n",
    "    2. FFT \n",
    "    \n",
    "2. Action(label) encoding\n",
    "    1. str - int - one_hot\n",
    "    \n",
    "\"\"\"\n",
    "action_dict = {\"1\": 0, \"2\": 1, \"3\": 2, \"4\": 3, \"5\": 4, \"6\": 5, \"7\": 6, \"8\": 7}\n",
    "\n",
    "\n",
    "def axisData_split(sensor_data, interval_len):\n",
    "    \"\"\"\n",
    "    split sensor data into small interval, for LSTM unit training\n",
    "    sensor_data: numpy.array with shape [seq_len, 8]\n",
    "    interval_len: int, the length of the resulting small interval\n",
    "    :return: list of numpy.array with shape [seq_len/interval_len, interval_len. 8]\n",
    "    \"\"\"\n",
    "    assert type(interval_len) == int\n",
    "    result = []\n",
    "    # print(len(sensor_data[0]) / tao)\n",
    "    start, end = 0, interval_len\n",
    "    while end <= len(sensor_data):\n",
    "        result.append(sensor_data[start:end])\n",
    "        start = end\n",
    "        end += interval_len\n",
    "    return result\n",
    "\n",
    "\n",
    "def dim_expansion(data):\n",
    "    \"\"\"\n",
    "    add the fourth dim for the original\n",
    "    :param data: numpy.array ax, ay, az, mx, my, mz data with shape [interval_len, 6]\n",
    "    :return: numpy.array with shape [interval_len, 8]\n",
    "    \"\"\"\n",
    "    data_new = np.zeros((data.shape[0], 8), dtype=float)\n",
    "    for i in range(data.shape[0]):\n",
    "        original_axis_index = 0\n",
    "        for j in range(8):\n",
    "            if j != 3 and j != 7:\n",
    "                data_new[i][j] = data[i][original_axis_index]\n",
    "                original_axis_index += 1\n",
    "            else:\n",
    "                data_new[i][j] = np.sqrt(\n",
    "                    np.power(data_new[i][j - 1], 2) + np.power(data_new[i][j - 2], 2) + np.power(data_new[i][j - 3],\n",
    "                                                                                                 2))\n",
    "    return data_new\n",
    "\n",
    "\n",
    "def feature_extraction_dict(data_np, dim=4, tao=0.5, freq=50):\n",
    "    \"\"\"Feature extraction for each data sample, FFT, frequency and magnitude\"\"\"\n",
    "    data_feature = []\n",
    "    if data_np.shape[0] < data_np.shape[1]:\n",
    "        data_np = np.rollaxis(data_np, 1, 0)\n",
    "    if dim == 4:\n",
    "        data_expand = dim_expansion(data_np)\n",
    "        # print(val_expand.shape)\n",
    "        # sys.exit()\n",
    "    else:\n",
    "        data_expand = data_np\n",
    "    # small_interval_len = int(freq * tao)  # [lstm_len, interval_len, 8]\n",
    "    #     small_interval_len = int(freq * tao)\n",
    "    small_interval_len = 12\n",
    "    axis_split_result = axisData_split(sensor_data=data_expand, interval_len=small_interval_len)\n",
    "    # feature extraction                  # [lstm_len. interval_len/2, 16]\n",
    "    sample_feature = []\n",
    "    for lstm_unit in axis_split_result:  #\n",
    "        unit_feature = []\n",
    "        for i in range(lstm_unit.shape[-1]):\n",
    "            # fft_result = np.fft.fft(lstm_unit[:, i]) / len(lstm_unit)\n",
    "            fft_result = np.fft.fft(lstm_unit[:, i])\n",
    "            amplitutde = np.sqrt(np.power(fft_result.real, 2) + np.power(fft_result.imag, 2))\n",
    "            amplitutde = amplitutde[0:int(len(lstm_unit) / 2) + 1]\n",
    "            freq_val = np.array([val * float(freq) / float(len(lstm_unit)) for val in\n",
    "                                 range(int(len(lstm_unit) / 2) + 1)])\n",
    "            unit_feature.append(freq_val)\n",
    "            unit_feature.append(amplitutde)\n",
    "        sample_feature.append(np.array(unit_feature))\n",
    "    return np.array(sample_feature)\n",
    "\n",
    "\n",
    "def action_encoding(act, one_hot=False):\n",
    "    act_int = action_dict[act]\n",
    "    if one_hot:\n",
    "        result = np.zeros(len(action_dict), dtype=int)\n",
    "        result[act_int] = 1\n",
    "        return result\n",
    "    else:\n",
    "        return act_int\n",
    "    \n",
    "\n",
    "def data_process_sensor(data_str, length=150):\n",
    "    data_list = data_str.strip().split(\",\")\n",
    "    acc_x = []\n",
    "    acc_y = []\n",
    "    acc_z = []\n",
    "    for i in range(int(len(data_list) / 3)):\n",
    "        acc_x.append(float(data_list[i * 3]))\n",
    "        acc_y.append(float(data_list[i * 3 + 1]))\n",
    "        acc_z.append(float(data_list[i * 3 + 2]))\n",
    "    acc_x = np.array(acc_x[0:length])\n",
    "    acc_y = np.array(acc_y[0:length])\n",
    "    acc_z = np.array(acc_z[0:length])\n",
    "    return np.stack([acc_x, acc_y, acc_z], axis=0)    \n",
    "    \n",
    "    \n",
    "def feature_extract(in_dir, out_dir, one_hot=False):\n",
    "    if not os.path.isdir(out_dir):\n",
    "        os.mkdir(out_dir)    \n",
    "    filelist = [val for val in os.listdir(in_dir)]\n",
    "    for file in filelist:\n",
    "        result = {\"label\": [], \"feature\": []}    # result for all samples stored in this file\n",
    "        data = open(os.path.join(in_dir, file))\n",
    "        for line in data:\n",
    "            uid, act, acc, gyro = line.strip().split(\"\\t\") \n",
    "            # action\n",
    "            act_enc = action_encoding(act, one_hot=one_hot)\n",
    "            # sensor singal, [2 * 3, length] (length = 150)\n",
    "            signal = np.concatenate((data_process_sensor(acc), data_process_sensor(gyro)), axis=0)\n",
    "            # frequency\n",
    "            acc_freq = (len(acc.split(\",\")) + len(gyro.split(\",\"))) / 14.0  # 7's \n",
    "            # feature\n",
    "            result[\"feature\"].append(feature_extraction_dict(signal, dim=4, tao=0.5, freq=acc_freq))\n",
    "            result[\"label\"].append(act_enc)\n",
    "        \n",
    "        save_pickle(result, os.path.join(out_dir, file.split(\".\")[0] + \".pickle\"))\n",
    "    print(\"Done !\")\n",
    "\n",
    "# in_dir = \"\"\n",
    "# out_dir = \"\"\n",
    "# feature_extract(in_dir, out_dir, one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
